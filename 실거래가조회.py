import streamlit as st
import pandas as pd
import requests
import xml.etree.ElementTree as ET
import urllib.parse
import os
import re
from datetime import datetime, timedelta
from fuzzywuzzy import process

#ì‹¤í–‰í•  ë•Œ í„°ë¯¸ë„ì—ì„œ "streamlit run C:\Users\user\PycharmProjects\ì‹¤ê±°ë˜ê°€ì¡°íšŒ\.venv\Scripts\ì‹¤ê±°ë˜ê°€ì¡°íšŒ.py" ì…ë ¥


# âœ… ê¸°ë³¸ CSV íŒŒì¼ì˜ ë¡œì»¬ ê²½ë¡œ (ì‚¬ìš©ìê°€ ì§ì ‘ ì„¤ì • ê°€ëŠ¥)
LOCAL_CSV_PATH = "C:/Users/user/PycharmProjects/ì‹¤ê±°ë˜ê°€ì¡°íšŒ/.venv/Scripts/ë²•ì •ë™ì½”ë“œ_default.csv"


@st.cache_data
def load_data(uploaded_file):
    """CSV íŒŒì¼ì„ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜"""

    # âœ… 1. ì‚¬ìš©ìê°€ íŒŒì¼ ì—…ë¡œë“œí•œ ê²½ìš° â†’ ì—…ë¡œë“œëœ íŒŒì¼ ì‚¬ìš©
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
        st.write("ğŸ“‚ ì—…ë¡œë“œëœ CSV íŒŒì¼ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return df

    # âœ… 2. ë¡œì»¬ ì»´í“¨í„°ì˜ ì§€ì •ëœ ê²½ë¡œì—ì„œ íŒŒì¼ ìë™ ë¡œë“œ
    elif os.path.exists(LOCAL_CSV_PATH):
        df = pd.read_csv(LOCAL_CSV_PATH, encoding='utf-8-sig')
        st.write(f"ğŸ“‚ ë¡œì»¬ íŒŒì¼ ìë™ ë¡œë“œ: {LOCAL_CSV_PATH}")
        return df

    # âœ… 3. íŒŒì¼ì´ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥
    else:
        st.error("âš  ë²•ì •ë™ ì½”ë“œ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        return None

def find_best_match_juridical_code(address, df):
    """ì…ë ¥ëœ ì£¼ì†Œì—ì„œ ë²•ì •ë™ ì½”ë“œ ì°¾ê¸°"""
    #st.write(f"ğŸ” [ë²•ì •ë™ ì½”ë“œ ì°¾ê¸°] ì…ë ¥ëœ ì£¼ì†Œ: {address}")

    if df is None:
        st.error("âš  ë²•ì •ë™ ì½”ë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    address_parts = address.split()
    matched_rows = df[df['ë²•ì •ë™ëª…'].apply(lambda x: any(part in x for part in address_parts))]

    #st.write(f"ğŸ“Œ [ë²•ì •ë™ ì½”ë“œ ê²€ìƒ‰] í•„í„°ë§ëœ í–‰ ê°œìˆ˜: {matched_rows.shape[0]}")
    #if not matched_rows.empty:
        #st.write("ğŸ“‹ [í•„í„°ë§ëœ ë²•ì •ë™ëª… ëª©ë¡]:")
        #st.write(matched_rows[['ë²•ì •ë™ëª…', 'ë²•ì •ì½”ë“œ_5ìë¦¬']])

    if matched_rows.empty:
        st.error("âš  ì…ë ¥í•œ ì£¼ì†Œì— í•´ë‹¹í•˜ëŠ” ë²•ì •ë™ ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    matched_rows['match_count'] = matched_rows['ë²•ì •ë™ëª…'].apply(lambda x: sum(part in x for part in address_parts))
    best_match_row = matched_rows.sort_values(by=['match_count', 'ë²•ì •ë™ëª…'], ascending=[False, False]).iloc[0]

    st.write(f"ğŸ“ [ë²•ì •ë™ ì½”ë“œ] ì°¾ì€ ë²•ì •ë™ëª…: {best_match_row['ë²•ì •ë™ëª…']} | ë²•ì •ë™ ì½”ë“œ: {best_match_row['ë²•ì •ì½”ë“œ_5ìë¦¬']}")
    return best_match_row[['ë²•ì •ë™ëª…', 'ë²•ì •ì½”ë“œ_5ìë¦¬']]

def extract_region_jibun(address):
    """ì£¼ì†Œì—ì„œ 'ì/ë©´/ë™/ë¦¬' ê°’ê³¼ ì§€ë²ˆ(ìˆ«ì) ì¶”ì¶œ"""
    match = re.search(r'(\S+ì|\S+ë©´|\S+ë™|\S+ë¦¬)\s+(\d+)', address)
    if match:
        return match.group(1), match.group(2)
    return None, None

def get_real_estate_data(lawd_cd, deal_ymd_list, service_key, region, jibun, apt_name):
    """APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì „ì²´ í˜ì´ì§€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´"""
    all_data = []

    for deal_ymd in deal_ymd_list:
        encoded_service_key = urllib.parse.quote(service_key, safe='')
        page_no = 1
        num_of_rows = 100  # í•œ ë²ˆì— ê°€ì ¸ì˜¬ ë°ì´í„° ê°œìˆ˜ (ìµœëŒ€ 100)

        while True:
            url = f"http://apis.data.go.kr/1613000/RTMSDataSvcAptTrade/getRTMSDataSvcAptTrade?LAWD_CD={lawd_cd}&DEAL_YMD={deal_ymd}&serviceKey={encoded_service_key}&numOfRows={num_of_rows}&pageNo={page_no}"

            #st.write(f"ğŸ” [API ìš”ì²­] í˜ì´ì§€ {page_no}: {url}")

            try:
                response = requests.get(url)
                response.raise_for_status()
                root = ET.fromstring(response.text)

                # âœ… totalCount ê°’ì„ í™•ì¸í•˜ì—¬ ì „ì²´ í˜ì´ì§€ ìˆ˜ ê³„ì‚°
                if page_no == 1:
                    total_count = int(root.findtext(".//totalCount", "0"))
                    #st.write(f"ğŸ“Š [ì´ ë°ì´í„° ê°œìˆ˜]: {total_count}ê°œ")
                    if total_count == 0:
                        break  # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë°”ë¡œ ì¢…ë£Œ

                item_count = 0
                for i, item in enumerate(root.findall(".//item")):
                    try:
                        item_apt_name = item.findtext("aptNm", "").strip()
                        item_umd = item.findtext("umdNm", "").strip()
                        item_jibun = item.findtext("jibun", "").strip()

                        match_type = None

                        # âœ… 1ìˆœìœ„: ì/ë©´/ë™/ë¦¬ + ì§€ë²ˆ ë§¤ì¹­
                        if region and jibun and region in item_umd and jibun in item_jibun:
                            match_type = "ì/ë©´/ë™/ë¦¬ + ì§€ë²ˆ ë§¤ì¹­"
                        # âœ… 2ìˆœìœ„: ì•„íŒŒíŠ¸ëª… ë§¤ì¹­
                        elif apt_name and apt_name in item_apt_name:
                            match_type = "ì•„íŒŒíŠ¸ëª… ë§¤ì¹­"

                        if match_type:
                            all_data.append({
                                "ë§¤ì¹­ìœ í˜•": match_type,
                                "ì•„íŒŒíŠ¸ëª…": item_apt_name,
                                "ì—°ë„": item.findtext("dealYear", "").replace(",", ""),
                                "ì›”": int(item.findtext("dealMonth", "")),
                                "ë©´ì ": float(item.findtext("excluUseAr", "")),
                                "ì¸µ": int(item.findtext("floor", "")),
                                "ê±°ë˜ê¸ˆì•¡(ë§Œì›)": int(item.findtext("dealAmount", "").replace(",", ""))
                            })
                        item_count += 1
                    except Exception as row_error:
                        st.write(f"âš  [ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜] í–‰ {i+1}: {row_error}")

                if item_count < num_of_rows:
                    break  # í˜„ì¬ í˜ì´ì§€ ë°ì´í„° ê°œìˆ˜ê°€ num_of_rowsë³´ë‹¤ ì‘ìœ¼ë©´ ë§ˆì§€ë§‰ í˜ì´ì§€ì„
                page_no += 1  # ë‹¤ìŒ í˜ì´ì§€ ìš”ì²­

            except requests.exceptions.RequestException as e:
                st.error(f"âš  API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                break  # ì—ëŸ¬ ë°œìƒ ì‹œ ë£¨í”„ ì¤‘ë‹¨

    return pd.DataFrame(all_data) if all_data else None

st.title("ë²•ì •ë™ ì½”ë“œ ê²€ìƒ‰ ë° ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ ì¡°íšŒ í”„ë¡œê·¸ë¨")

uploaded_file = st.file_uploader("ë²•ì •ë™ ì½”ë“œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì„ íƒ ì‚¬í•­)", type=["csv"])
df = load_data(uploaded_file)

address = st.text_input("ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
# í˜„ì¬ ì—°ë„ì™€ ì›”ì„ ê°€ì ¸ì˜´
current_year = datetime.today().year  # 2025
current_month = datetime.today().month  # 3

# ìµœê·¼ 5ë…„ê°„ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ë¦¬ìŠ¤íŠ¸ ìƒì„±
deal_ymd_list = [
    f"{y}{m:02d}"
    for y in range(current_year - 5, current_year + 1)  # ìµœê·¼ 5ë…„ (2020 ~ 2025)
    for m in range(1, 13)  # 1ì›”~12ì›” ë°˜ë³µ
    if not (y == current_year and m > current_month)  # ë¯¸ë˜ ë°ì´í„°(2025ë…„ 4ì›” ì´í›„)ëŠ” ì œì™¸
]

# âœ… Streamlit Cloud Secretsì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
if "service_key" in st.secrets:
    service_key = st.secrets["service_key"]
    st.write("âœ… API í‚¤ê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
else:
    st.error("âš  API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Streamlit Secrets ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”!")
    st.stop()  # ì‹¤í–‰ ì¤‘ë‹¨

if address and df is not None:
    region, jibun = extract_region_jibun(address)

    # âœ… ë²•ì •ë™ ì½”ë“œ ì°¾ê¸° (ìˆ˜ì •)
    result = find_best_match_juridical_code(address, df)

    if result is None:
        st.error("âš  ë²•ì •ë™ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì‹¤ê±°ë˜ê°€ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    lawd_cd = result['ë²•ì •ì½”ë“œ_5ìë¦¬']

    real_estate_data = get_real_estate_data(lawd_cd, deal_ymd_list, service_key, region, jibun, None)

    if real_estate_data is not None and not real_estate_data.empty:
        st.write("ğŸ¢ ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ ë°ì´í„° (ë©´ì ë³„ ì •ë¦¬):")
        grouped_data = real_estate_data.groupby("ë©´ì ")
        st.write(f"ğŸ”¹ ë©´ì ë³„ í…Œì´ë¸” ê°œìˆ˜: {len(grouped_data)}")
        for area, group in grouped_data:
            st.write(f"ğŸ  **ë©´ì : {area} mÂ²**")
            st.dataframe(group.sort_values(by=['ì—°ë„', 'ì›”'], ascending=[False, False]))
    else:
        st.write("âš  í•´ë‹¹ ì§€ì—­ì˜ ì‹¤ê±°ë˜ê°€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")