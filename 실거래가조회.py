import streamlit as st
import pandas as pd
import requests
import xml.etree.ElementTree as ET
import urllib.parse
import os
import re
from datetime import datetime, timedelta
from fuzzywuzzy import process

# âœ… Airtable API ì„¤ì • (Streamlit Secretsì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°)
if "secrets" in st.secrets and "airtable_api_key" in st.secrets["secrets"]:
    airtable_api_key = st.secrets["secrets"]["airtable_api_key"]
    airtable_base_id = st.secrets["secrets"]["airtable_base_id"]
    airtable_table_name = st.secrets["secrets"]["airtable_table_name"]
else:
    st.error("âš  Airtable API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Secretsì—ì„œ í™•ì¸í•˜ì„¸ìš”!")
    st.stop()

# âœ… Airtable API URL ì„¤ì •
airtable_url = f"https://api.airtable.com/v0/{airtable_base_id}/{airtable_table_name}"


# âœ… Airtable API í˜¸ì¶œ í•¨ìˆ˜ (ì¶œë ¥ëœ ë°ì´í„°ì— ë§ì¶° ì»¬ëŸ¼ëª… ìˆ˜ì •)
# âœ… Airtable API í˜¸ì¶œ í•¨ìˆ˜ (ì „ì²´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°)
def fetch_airtable_data():
    headers = {"Authorization": f"Bearer {airtable_api_key}"}
    all_records = []
    offset = None

    while True:
        params = {}
        if offset:
            params["offset"] = offset  # ë‹¤ìŒ í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°

        response = requests.get(airtable_url, headers=headers, params=params)
        if response.status_code != 200:
            st.error(f"âš  Airtable API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            return None

        data = response.json()
        records = data.get("records", [])
        all_records.extend(records)

        # âœ… `offset`ì´ ìˆìœ¼ë©´ ê³„ì† ê°€ì ¸ì˜¤ê¸°
        offset = data.get("offset")
        if not offset:
            break  # ëª¨ë“  ë°ì´í„° ê°€ì ¸ì™”ìœ¼ë©´ ì¢…ë£Œ

    # âœ… ì´ ê°œìˆ˜ í™•ì¸
    #st.write(f"ğŸ“Š Airtableì—ì„œ ê°€ì ¸ì˜¨ ì´ ë°ì´í„° ê°œìˆ˜: {len(all_records)}ê°œ")

    # âœ… ë³€í™˜ëœ ë°ì´í„° ì €ì¥
    data_list = []
    for record in all_records:
        fields = record.get("fields", {})
        data_list.append({
            "ë²•ì •ë™ëª…": fields.get("ë²•ì •ë™ì½”ë“œ", ""),  # âœ… ì»¬ëŸ¼ëª… ìˆ˜ì •
            "ë²•ì •ì½”ë“œ_5ìë¦¬": fields.get("ë²•ì •ë™ëª…", "")  # âœ… ì»¬ëŸ¼ëª… ìˆ˜ì •
        })

    if data_list:
        df = pd.DataFrame(data_list)
        #st.write("ğŸ“‹ Airtableì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°:")
        #st.dataframe(df)  # âœ… ìµœì¢… ë°ì´í„° ì¶œë ¥
        return df
    else:
        st.error("âš  Airtableì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

# âœ… ë°ì´í„° ë¡œë”© í•¨ìˆ˜ (Airtable â†’ CSV íŒŒì¼ ìˆœì„œ)
@st.cache_data
def load_data(uploaded_file):
    """Airtable ë°ì´í„°ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , ì‹¤íŒ¨í•˜ë©´ CSV íŒŒì¼ì„ ì‚¬ìš©"""

    # âœ… 1. Airtableì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹œë„
    df = fetch_airtable_data()
    if df is not None:
        return df  # Airtable ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ë©´ ë°˜í™˜

    # âœ… 2. Airtable ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ ì‹œ ì—…ë¡œë“œëœ CSV íŒŒì¼ ì‚¬ìš©
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
        st.write("ğŸ“‚ Airtable ë¡œë”© ì‹¤íŒ¨, ì—…ë¡œë“œëœ CSV íŒŒì¼ì„ ëŒ€ì‹  ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return df

    # âœ… 3. CSV íŒŒì¼ë„ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥
    else:
        st.error("âš  ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Airtableê³¼ CSV íŒŒì¼ì´ ëª¨ë‘ ì—†ì–´ìš”.")
        return None

def find_best_match_juridical_code(address, df):
    """ì…ë ¥ëœ ì£¼ì†Œì—ì„œ ë²•ì •ë™ ì½”ë“œ ì°¾ê¸°"""
    #st.write(f"ğŸ” [ë²•ì •ë™ ì½”ë“œ ì°¾ê¸°] ì…ë ¥ëœ ì£¼ì†Œ: {address}")

    if df is None:
        st.error("âš  ë²•ì •ë™ ì½”ë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    address_parts = address.split()
    matched_rows = df[df['ë²•ì •ë™ëª…'].apply(lambda x: any(part in x for part in address_parts))]

    #st.write(f"ğŸ“Œ [ë²•ì •ë™ ì½”ë“œ ê²€ìƒ‰] í•„í„°ë§ëœ í–‰ ê°œìˆ˜: {matched_rows.shape[0]}")
    #if not matched_rows.empty:
        #st.write("ğŸ“‹ [í•„í„°ë§ëœ ë²•ì •ë™ëª… ëª©ë¡]:")
        #st.write(matched_rows[['ë²•ì •ë™ëª…', 'ë²•ì •ì½”ë“œ_5ìë¦¬']])

    if matched_rows.empty:
        st.error("âš  ì…ë ¥í•œ ì£¼ì†Œì— í•´ë‹¹í•˜ëŠ” ë²•ì •ë™ ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    matched_rows['match_count'] = matched_rows['ë²•ì •ë™ëª…'].apply(lambda x: sum(part in x for part in address_parts))
    best_match_row = matched_rows.sort_values(by=['match_count', 'ë²•ì •ë™ëª…'], ascending=[False, False]).iloc[0]

    st.write(f"ğŸ“ [ë²•ì •ë™ ì½”ë“œ] ì°¾ì€ ë²•ì •ë™ëª…: {best_match_row['ë²•ì •ë™ëª…']} | ë²•ì •ë™ ì½”ë“œ: {best_match_row['ë²•ì •ì½”ë“œ_5ìë¦¬']}")
    return best_match_row[['ë²•ì •ë™ëª…', 'ë²•ì •ì½”ë“œ_5ìë¦¬']]

def extract_region_jibun(address):
    """ì£¼ì†Œì—ì„œ 'ì/ë©´/ë™/ë¦¬' ê°’ê³¼ ì§€ë²ˆ(ìˆ«ì) ì¶”ì¶œ"""
    match = re.search(r'(\S+ì|\S+ë©´|\S+ë™|\S+ë¦¬)\s+(\d+)', address)
    if match:
        return match.group(1), match.group(2)
    return None, None

def get_real_estate_data(lawd_cd, deal_ymd_list, service_key, region, jibun, apt_name):
    """APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì „ì²´ í˜ì´ì§€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´"""
    all_data = []

    for deal_ymd in deal_ymd_list:
        encoded_service_key = urllib.parse.quote(service_key, safe='')
        page_no = 1
        num_of_rows = 100  # í•œ ë²ˆì— ê°€ì ¸ì˜¬ ë°ì´í„° ê°œìˆ˜ (ìµœëŒ€ 100)

        while True:
            url = f"http://apis.data.go.kr/1613000/RTMSDataSvcAptTrade/getRTMSDataSvcAptTrade?LAWD_CD={lawd_cd}&DEAL_YMD={deal_ymd}&serviceKey={encoded_service_key}&numOfRows={num_of_rows}&pageNo={page_no}"

            #st.write(f"ğŸ” [API ìš”ì²­] í˜ì´ì§€ {page_no}: {url}")

            try:
                response = requests.get(url)
                response.raise_for_status()
                root = ET.fromstring(response.text)

                # âœ… totalCount ê°’ì„ í™•ì¸í•˜ì—¬ ì „ì²´ í˜ì´ì§€ ìˆ˜ ê³„ì‚°
                if page_no == 1:
                    total_count = int(root.findtext(".//totalCount", "0"))
                    #st.write(f"ğŸ“Š [ì´ ë°ì´í„° ê°œìˆ˜]: {total_count}ê°œ")
                    if total_count == 0:
                        break  # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë°”ë¡œ ì¢…ë£Œ

                item_count = 0
                for i, item in enumerate(root.findall(".//item")):
                    try:
                        item_apt_name = item.findtext("aptNm", "").strip()
                        item_umd = item.findtext("umdNm", "").strip()
                        item_jibun = item.findtext("jibun", "").strip()

                        match_type = None

                        # âœ… 1ìˆœìœ„: ì/ë©´/ë™/ë¦¬ + ì§€ë²ˆ ë§¤ì¹­
                        if region and jibun and region in item_umd and jibun in item_jibun:
                            match_type = "ì/ë©´/ë™/ë¦¬ + ì§€ë²ˆ ë§¤ì¹­"
                        # âœ… 2ìˆœìœ„: ì•„íŒŒíŠ¸ëª… ë§¤ì¹­
                        elif apt_name and apt_name in item_apt_name:
                            match_type = "ì•„íŒŒíŠ¸ëª… ë§¤ì¹­"

                        if match_type:
                            all_data.append({
                                "ë§¤ì¹­ìœ í˜•": match_type,
                                "ì•„íŒŒíŠ¸ëª…": item_apt_name,
                                "ì—°ë„": item.findtext("dealYear", "").replace(",", ""),
                                "ì›”": int(item.findtext("dealMonth", "")),
                                "ë©´ì ": float(item.findtext("excluUseAr", "")),
                                "ì¸µ": int(item.findtext("floor", "")),
                                "ê±°ë˜ê¸ˆì•¡(ë§Œì›)": int(item.findtext("dealAmount", "").replace(",", ""))
                            })
                        item_count += 1
                    except Exception as row_error:
                        st.write(f"âš  [ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜] í–‰ {i+1}: {row_error}")

                if item_count < num_of_rows:
                    break  # í˜„ì¬ í˜ì´ì§€ ë°ì´í„° ê°œìˆ˜ê°€ num_of_rowsë³´ë‹¤ ì‘ìœ¼ë©´ ë§ˆì§€ë§‰ í˜ì´ì§€ì„
                page_no += 1  # ë‹¤ìŒ í˜ì´ì§€ ìš”ì²­

            except requests.exceptions.RequestException as e:
                st.error(f"âš  API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                break  # ì—ëŸ¬ ë°œìƒ ì‹œ ë£¨í”„ ì¤‘ë‹¨

    return pd.DataFrame(all_data) if all_data else None

st.title("ë²•ì •ë™ ì½”ë“œ ê²€ìƒ‰ ë° ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ ì¡°íšŒ í”„ë¡œê·¸ë¨")

uploaded_file = st.file_uploader("ë²•ì •ë™ ì½”ë“œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì„ íƒ ì‚¬í•­)")
df = fetch_airtable_data()

if df is not None:
    #st.write(f"ğŸ“‹ ìµœì¢… ë¡œë“œëœ ë²•ì •ë™ ì½”ë“œ ë°ì´í„° (ì´ {len(df)}ê°œ):")
    st.dataframe(df)
else:
    st.error("âš  ë²•ì •ë™ ì½”ë“œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

address = st.text_input("ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
# í˜„ì¬ ì—°ë„ì™€ ì›”ì„ ê°€ì ¸ì˜´
current_year = datetime.today().year  # 2025
current_month = datetime.today().month  # 3

# ìµœê·¼ 5ë…„ê°„ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ë¦¬ìŠ¤íŠ¸ ìƒì„±
deal_ymd_list = [
    f"{y}{m:02d}"
    for y in range(current_year - 3, current_year + 1)  # ìµœê·¼ 3ë…„ (2022 ~ 2025)
    for m in range(1, 13)  # 1ì›”~12ì›” ë°˜ë³µ
    if not (y == current_year and m > current_month)  # ë¯¸ë˜ ë°ì´í„°(2025ë…„ 4ì›” ì´í›„)ëŠ” ì œì™¸
]

# âœ… ì¤‘ì²©ëœ êµ¬ì¡°ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
if "secrets" in st.secrets and "service_key" in st.secrets["secrets"]:
    service_key = st.secrets["secrets"]["service_key"]
    #st.write("âœ… API í‚¤ê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤:", service_key[:5] + "*****")
else:
    st.error("âš  API í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Streamlit Secrets ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”!")
    st.stop()  # ì‹¤í–‰ ì¤‘ë‹¨

if address and df is not None:
    region, jibun = extract_region_jibun(address)

    # âœ… ë²•ì •ë™ ì½”ë“œ ì°¾ê¸° (ìˆ˜ì •)
    result = find_best_match_juridical_code(address, df)

    if result is None:
        st.error("âš  ë²•ì •ë™ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì‹¤ê±°ë˜ê°€ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    lawd_cd = result['ë²•ì •ì½”ë“œ_5ìë¦¬']

    real_estate_data = get_real_estate_data(lawd_cd, deal_ymd_list, service_key, region, jibun, None)

    if real_estate_data is not None and not real_estate_data.empty:
        st.write("ğŸ¢ ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ ë°ì´í„° (ë©´ì ë³„ ì •ë¦¬):")
        grouped_data = real_estate_data.groupby("ë©´ì ")
        st.write(f"ğŸ”¹ ë©´ì ë³„ í…Œì´ë¸” ê°œìˆ˜: {len(grouped_data)}")
        for area, group in grouped_data:
            st.write(f"ğŸ  **ë©´ì : {area} mÂ²**")
            st.dataframe(group.sort_values(by=['ì—°ë„', 'ì›”'], ascending=[False, False]))
    else:
        st.write("âš  í•´ë‹¹ ì§€ì—­ì˜ ì‹¤ê±°ë˜ê°€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")